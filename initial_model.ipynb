{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x):\n",
    "\n",
    "  norm_squared = (x ** 2).sum(-1, keepdim=True)\n",
    "  part1 = norm_squared / (1 +  norm_squared)\n",
    "  part2 = x / torch.sqrt(norm_squared)\n",
    "\n",
    "  output = part1 * part2 \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "  def __init__(self, \n",
    "               in_channels=1, \n",
    "               out_channels=256, \n",
    "               kernel_size=9):\n",
    "    super(ConvLayer, self).__init__()\n",
    "    \n",
    "    self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=1)\n",
    "  def forward(self, x):\n",
    "    output = self.conv(x)\n",
    "    output = functional.relu(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCapules(nn.Module):\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_capsules=8, \n",
    "               in_channels=256, \n",
    "               out_channels=32, \n",
    "               kernel_size=9):\n",
    "    super(PrimaryCapules, self).__init__()\n",
    "    self.capsules = nn.ModuleList([\n",
    "      nn.Conv2d(in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=2,\n",
    "                padding=0) for i in range(num_capsules)\n",
    "    ])\n",
    "  \n",
    "  def forward(self, x):\n",
    "    output = [caps(x) for caps in self.capsules]\n",
    "    output = torch.stack(output, dim=1)\n",
    "    output = output.view(x.size(0), 32*6*6, -1)\n",
    "    \n",
    "    return squash(output)\n",
    "  \n",
    "  # The squash function specified in Dynamic Routing Between Capsules\n",
    "  # x: input tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassCapsules(nn.Module):\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_capsules=10,\n",
    "               num_routes = 32*6*6,\n",
    "               in_channels=8,\n",
    "               out_channels=16,\n",
    "               routing_iterations=3):\n",
    "    super(ClassCapsules, self).__init__()\n",
    "    \n",
    "    self.in_channels = in_channels\n",
    "    self.num_routes = num_routes\n",
    "    self.num_capsules = num_capsules\n",
    "    self.routing_iterations = routing_iterations\n",
    "    self.W = nn.Parameter(torch.rand(1,\n",
    "                                     num_routes,\n",
    "                                     num_capsules,\n",
    "                                     out_channels,\n",
    "                                     in_channels))\n",
    "  \n",
    "  def forward(self, x):\n",
    "    batch_size = x.size(0)\n",
    "    x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "    \n",
    "    W = torch.cat([self.W] * batch_size, dim=0)\n",
    "    u_hat = torch.matmul(W, x)\n",
    "    \n",
    "    b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "    \n",
    "    if USE_GPU:\n",
    "      b_ij = b_ij.cuda()\n",
    "    \n",
    "    for it in range(self.routing_iterations):\n",
    "      c_ij = functional.softmax(b_ij, dim=1) # Not sure if it should be dim=1\n",
    "      c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "      \n",
    "      s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "      v_j = squash(s_j)\n",
    "      \n",
    "      if it < self.routing_iterations - 1: \n",
    "        uhatv_product = torch.matmul(u_hat.transpose(3,4),\n",
    "                            torch.cat([v_j] * self.num_routes, dim=1))\n",
    "        uhatv_product = uhatv_product.squeeze(4).mean(dim=0, keepdim=True)\n",
    "        b_ij = b_ij + uhatv_product\n",
    "      \n",
    "    return v_j.squeeze(1)\n",
    "\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionModule(nn.Module):\n",
    "  def __init__(self, capsule_size=16, num_capsules=10):\n",
    "    super(ReconstructionModule, self).__init__()\n",
    "    \n",
    "    self.num_capsules = num_capsules\n",
    "    self.capsule_size = capsule_size\n",
    "    \n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(capsule_size*num_capsules, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 1024),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(1024, 784),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  def forward(self, x, data, target=None):\n",
    "    batch_size = x.size(0)\n",
    "    if target is None:\n",
    "      classes = torch.sqrt((x **2).sum(2))\n",
    "      classes = functional.softmax(classes, dim=1)\n",
    "\n",
    "      _, max_length_indices = classes.max(dim=1)\n",
    "    else:\n",
    "      max_length_indices = target.max(dim=1)[1].reshape(-1,1)\n",
    "    masked = Variable(torch.eye(self.num_capsules))\n",
    "    \n",
    "    if USE_GPU:\n",
    "      masked  = masked.cuda()\n",
    "    masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
    "    decoder_input = (x * masked[:, :, None, None]).view(batch_size, -1)\n",
    "\n",
    "    reconstructions = self.decoder(decoder_input)\n",
    "    reconstructions = reconstructions.view(-1, 1, 28, 28)\n",
    "    \n",
    "    return reconstructions, masked\n",
    "\n",
    "    \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "  \n",
    "  def __init__(self,\n",
    "               alpha=0.0005 # Alpha from the loss function \n",
    "              ):\n",
    "    super(CapsNet, self).__init__()\n",
    "    \n",
    "    self.conv_layer = ConvLayer()\n",
    "    self.primary_capsules = PrimaryCapules()\n",
    "    self.digit_caps = ClassCapsules()\n",
    "    self.decoder = ReconstructionModule()\n",
    "    \n",
    "    self.mse_loss = nn.MSELoss()\n",
    "    self.alpha = alpha\n",
    "  \n",
    "  def forward(self, x, target=None):\n",
    "    output = self.conv_layer(x)\n",
    "    output = self.primary_capsules(output)\n",
    "    output = self.digit_caps(output)\n",
    "    reconstruction, masked = self.decoder(output, x, target)\n",
    "    return output, reconstruction, masked\n",
    "  \n",
    "  def loss(self, images,labels, capsule_output,  reconstruction):\n",
    "    marg_loss = self.margin_loss(capsule_output, labels)\n",
    "    rec_loss = self.reconstruction_loss(data, reconstruction)\n",
    "    return marg_loss + self.alpha*rec_loss\n",
    "  \n",
    "  def margin_loss(self, x, labels):\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
    "    \n",
    "    left = functional.relu(0.9 - v_c).view(batch_size, -1)\n",
    "    right = functional.relu(v_c - 0.1).view(batch_size, -1)\n",
    "    \n",
    "    loss = labels * left + 0.5 *(1-labels)*right\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "    return loss\n",
    "  \n",
    "  def reconstruction_loss(self, data, reconstructions):\n",
    "    batch_size = reconstructions.size(0)\n",
    "    loss = self.mse_loss(reconstructions.view(batch_size, -1),\n",
    "                         data.view(batch_size, -1))\n",
    "    return loss\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(nn.DataParallel):\n",
    "  \n",
    "  def __init__(self, capsnet, device_ids):\n",
    "    super(Test, self).__init__(capsnet, device_ids=device_ids)\n",
    "    self.capsnet = capsnet\n",
    "    \n",
    "  def loss(self, images,labels, capsule_output,  reconstruction): \n",
    "    return self.capsnet.loss(images, labels, capsule_output, reconstruction)\n",
    "  \n",
    "  def initialize_weights(self, initializer):\n",
    "    self.capsnet.conv_layer.conv.apply(initializer)\n",
    "    self.capsnet.primary_capsules.apply(initializer)\n",
    "    self.capsnet.decoder.apply(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capsnet = Test(CapsNet(), device_ids=[0,1])\n",
    "if USE_GPU:\n",
    "  capsnet.cuda()\n",
    "optimizer = torch.optim.Adam(capsnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet.initialize_weights(weights_init_xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               transforms.Normalize((0.1307,), (0.3081,))\n",
    "           ])\n",
    "\"\"\"Hyperparameters\"\"\"\n",
    "max_epochs = 50\n",
    "batch_size = 128\n",
    "train_dataset = datasets.MNIST('../data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=dataset_transform)\n",
    "test_dataset = datasets.MNIST('../data', \n",
    "                               train=False, \n",
    "                               download=True, \n",
    "                               transform=dataset_transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 \t Time: 106 \t Test: 0.819 \t Train: 0.859 \t Accuracy: 36.6900\n",
      "Epoch:   1 \t Time: 103 \t Test: 0.756 \t Train: 0.779 \t Accuracy: 49.2800\n",
      "Epoch:   2 \t Time: 105 \t Test: 0.367 \t Train: 0.547 \t Accuracy: 81.0200\n",
      "Epoch:   3 \t Time: 106 \t Test: 0.188 \t Train: 0.253 \t Accuracy: 93.0800\n",
      "Epoch:   4 \t Time: 106 \t Test: 0.111 \t Train: 0.143 \t Accuracy: 95.8100\n",
      "Epoch:   5 \t Time: 105 \t Test: 0.098 \t Train: 0.104 \t Accuracy: 96.7800\n",
      "Epoch:   6 \t Time: 106 \t Test: 0.073 \t Train: 0.084 \t Accuracy: 97.6100\n",
      "Epoch:   7 \t Time: 106 \t Test: 0.072 \t Train: 0.072 \t Accuracy: 97.7700\n",
      "Epoch:   8 \t Time: 105 \t Test: 0.059 \t Train: 0.063 \t Accuracy: 98.0500\n",
      "Epoch:   9 \t Time: 103 \t Test: 0.050 \t Train: 0.056 \t Accuracy: 98.2300\n",
      "Epoch:  10 \t Time: 106 \t Test: 0.047 \t Train: 0.050 \t Accuracy: 98.4700\n",
      "Epoch:  11 \t Time: 103 \t Test: 0.043 \t Train: 0.046 \t Accuracy: 98.6500\n",
      "Epoch:  12 \t Time: 103 \t Test: 0.041 \t Train: 0.042 \t Accuracy: 98.6500\n",
      "Epoch:  13 \t Time: 104 \t Test: 0.041 \t Train: 0.040 \t Accuracy: 98.8200\n",
      "Epoch:  14 \t Time: 106 \t Test: 0.044 \t Train: 0.038 \t Accuracy: 98.5600\n",
      "Epoch:  15 \t Time: 105 \t Test: 0.033 \t Train: 0.034 \t Accuracy: 98.9600\n",
      "Epoch:  16 \t Time: 102 \t Test: 0.034 \t Train: 0.032 \t Accuracy: 98.9900\n",
      "Epoch:  17 \t Time: 104 \t Test: 0.033 \t Train: 0.030 \t Accuracy: 99.0500\n",
      "Epoch:  18 \t Time: 104 \t Test: 0.031 \t Train: 0.029 \t Accuracy: 98.9600\n",
      "Epoch:  19 \t Time: 103 \t Test: 0.030 \t Train: 0.027 \t Accuracy: 99.0600\n",
      "Epoch:  20 \t Time: 105 \t Test: 0.028 \t Train: 0.026 \t Accuracy: 99.0600\n",
      "Epoch:  21 \t Time: 104 \t Test: 0.026 \t Train: 0.024 \t Accuracy: 99.1500\n",
      "Epoch:  22 \t Time: 105 \t Test: 0.026 \t Train: 0.023 \t Accuracy: 99.1000\n",
      "Epoch:  23 \t Time: 105 \t Test: 0.025 \t Train: 0.021 \t Accuracy: 99.2900\n",
      "Epoch:  24 \t Time: 105 \t Test: 0.025 \t Train: 0.021 \t Accuracy: 99.2000\n",
      "Epoch:  25 \t Time: 104 \t Test: 0.025 \t Train: 0.020 \t Accuracy: 99.2000\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "Te_LOSS = []\n",
    "Tr_LOSS = []\n",
    "for epoch in range(max_epochs):\n",
    "  capsnet.train()\n",
    "  train_loss = 0\n",
    "  for batch, (data, target) in enumerate(train_loader):\n",
    "    target = torch.eye(10).index_select(dim=0, index=target)\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    \n",
    "    if USE_GPU:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, reconstructions, masked = capsnet(data, target)\n",
    "    loss = capsnet.loss(data, target, output, reconstructions)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.data.item()\n",
    "  \n",
    "  capsnet.eval()\n",
    "  test_loss = 0\n",
    "  test_correct = 0\n",
    "  test_total = 0\n",
    "  for batch_id, (data, target) in enumerate(test_loader):\n",
    "    target = torch.eye(10).index_select(dim=0, index=target)\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    \n",
    "    if USE_GPU:\n",
    "      data,target = data.cuda(), target.cuda()\n",
    "    \n",
    "    output, reconstruction, masked = capsnet(data)\n",
    "    loss = capsnet.loss(data, target, output, reconstruction)\n",
    "    \n",
    "    test_loss += loss.data.item()\n",
    "    test_total += data.size(0)\n",
    "    test_correct += sum(np.argmax(masked.data.cpu().numpy(),1 ) == np.argmax(target.data.cpu().numpy(), 1))\n",
    "  \n",
    "  acc = test_correct / test_total\n",
    "  Te_LOSS.append(test_loss / len(test_loader))\n",
    "  Tr_LOSS.append(train_loss / len(train_loader))\n",
    "  test_loss /= len(test_loader)\n",
    "  train_loss /= len(train_loader)\n",
    "  time_spent = time.time() - t\n",
    "  t = time.time()\n",
    "  print(\"Epoch: {:3.0f} \\t Time: {:3.0f} \\t Test: {:.3f} \\t Train: {:.3f} \\t Accuracy: {:3.4f}\".format(epoch, time_spent,test_loss, train_loss, acc*100))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[36.69, 49.28, 81.02, 93.08, 95.81, 96.78, 97.61, 97.77, 98.05, 98.23, 98.47, 98.6, 98.65, 98.82, 98.56, 98.96, 98.99,99.05,98.96]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
