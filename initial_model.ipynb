{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "USE_GPU = True\n",
    "from model import *\n",
    "from data_loaders import load_mnist\n",
    "from tools import weights_init_xavier\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as path\n",
    "SAVE_DIR = \"saved_models\"\n",
    "FILENAME = \"modelk.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(capsnet):\n",
    "  capsnet.conv_layer.conv.apply(weights_init_xavier)\n",
    "  capsnet.primary_capsules.apply(weights_init_xavier)\n",
    "  capsnet.decoder.apply(weights_init_xavier)\n",
    "  #nn.init.xavier_normal_(capsnet.digit_caps.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet = CapsNet(reconstruction_type=\"FC\")\n",
    "if USE_GPU:\n",
    "  capsnet.cuda()\n",
    "optimizer = torch.optim.Adam(capsnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model not found; Model initialized.\n"
     ]
    }
   ],
   "source": [
    "filepath = path.join(SAVE_DIR, FILENAME)\n",
    "if path.isfile(filepath):\n",
    "  print(\"Saved model found\")\n",
    "  capsnet.load_state_dict(torch.load(filepath))\n",
    "else:\n",
    "  print(\"Saved model not found; Model initialized.\")\n",
    "  initialize_weights(capsnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hyperparameters\"\"\"\n",
    "max_epochs = 1000\n",
    "batch_size = 128\n",
    "train_loader, test_loader = load_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  2.2360,  1.3577, -0.3860, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  2.7578,  2.8088, -0.2333, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.2333,  2.7706,  2.8215,  1.0523, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.8486,  2.8088,  2.8088,  1.1032, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           2.0578,  2.8088,  2.8088, -0.1315, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           2.1596,  2.8088,  2.0323, -0.3606, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.1740,\n",
       "           2.7324,  2.8088,  1.6887, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.1159,\n",
       "           2.8088,  2.8088,  0.8232, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3606,  2.6178,\n",
       "           2.8088,  2.5924,  0.0340, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3478,  2.8088,\n",
       "           2.8088,  2.0069, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3478,  2.8088,\n",
       "           2.8088,  0.9632, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.4159,  2.8088,\n",
       "           2.8088,  0.9632, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.4341,  2.8088,\n",
       "           2.8088,  0.5049, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.3224,  2.3633,  2.8088,\n",
       "           2.8088, -0.3606, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  0.3777,  2.8088,  2.8088,\n",
       "           1.9051, -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  0.4922,  2.8215,  2.8088,\n",
       "           0.3649, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.3606,  1.9942,  2.8088,  2.8088,\n",
       "           0.2377, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  0.3777,  2.8088,  2.8088,  1.6378,\n",
       "          -0.3224, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  0.8104,  2.8088,  2.8088,  0.8359,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.3860,  1.3577,  2.7578, -0.1951,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 \t Time: 106 \t Test: 0.455 \t Train: 0.691 \t Accuracy: 91.6700\n",
      "Epoch:   1 \t Time: 111 \t Test: 0.174 \t Train: 0.272 \t Accuracy: 97.9700\n",
      "Epoch:   2 \t Time: 112 \t Test: 0.124 \t Train: 0.138 \t Accuracy: 98.3500\n",
      "Epoch:   3 \t Time: 112 \t Test: 0.081 \t Train: 0.095 \t Accuracy: 98.6900\n",
      "Epoch:   4 \t Time: 111 \t Test: 0.054 \t Train: 0.059 \t Accuracy: 98.6800\n",
      "Epoch:   5 \t Time: 107 \t Test: 0.037 \t Train: 0.044 \t Accuracy: 98.9800\n",
      "Epoch:   6 \t Time: 112 \t Test: 0.044 \t Train: 0.034 \t Accuracy: 98.7600\n",
      "Epoch:   7 \t Time: 112 \t Test: 0.034 \t Train: 0.030 \t Accuracy: 99.1800\n",
      "Epoch:   8 \t Time: 112 \t Test: 0.040 \t Train: 0.028 \t Accuracy: 98.9100\n",
      "Epoch:   9 \t Time: 106 \t Test: 0.055 \t Train: 0.025 \t Accuracy: 98.9200\n",
      "Epoch:  10 \t Time: 112 \t Test: 0.035 \t Train: 0.024 \t Accuracy: 99.0600\n",
      "Epoch:  11 \t Time: 107 \t Test: 0.024 \t Train: 0.022 \t Accuracy: 99.3300\n",
      "Epoch:  12 \t Time: 111 \t Test: 0.033 \t Train: 0.021 \t Accuracy: 99.2700\n",
      "Epoch:  13 \t Time: 111 \t Test: 0.024 \t Train: 0.019 \t Accuracy: 99.2700\n",
      "Epoch:  14 \t Time: 111 \t Test: 0.022 \t Train: 0.018 \t Accuracy: 99.3900\n",
      "Epoch:  15 \t Time: 111 \t Test: 0.021 \t Train: 0.017 \t Accuracy: 99.3500\n",
      "Epoch:  16 \t Time: 109 \t Test: 0.024 \t Train: 0.017 \t Accuracy: 99.3200\n",
      "Epoch:  17 \t Time: 108 \t Test: 0.020 \t Train: 0.015 \t Accuracy: 99.4400\n",
      "Epoch:  18 \t Time: 111 \t Test: 0.024 \t Train: 0.015 \t Accuracy: 99.2600\n",
      "Epoch:  19 \t Time: 115 \t Test: 0.024 \t Train: 0.014 \t Accuracy: 99.3300\n",
      "Epoch:  20 \t Time: 115 \t Test: 0.027 \t Train: 0.013 \t Accuracy: 99.4000\n",
      "Epoch:  21 \t Time: 112 \t Test: 0.018 \t Train: 0.013 \t Accuracy: 99.3900\n",
      "Epoch:  22 \t Time: 109 \t Test: 0.020 \t Train: 0.012 \t Accuracy: 99.4300\n",
      "Epoch:  23 \t Time: 109 \t Test: 0.020 \t Train: 0.011 \t Accuracy: 99.3300\n",
      "Epoch:  24 \t Time: 109 \t Test: 0.021 \t Train: 0.011 \t Accuracy: 99.2100\n",
      "Epoch:  25 \t Time: 111 \t Test: 0.021 \t Train: 0.010 \t Accuracy: 99.2700\n",
      "Epoch:  26 \t Time: 109 \t Test: 0.020 \t Train: 0.010 \t Accuracy: 99.3300\n",
      "Epoch:  27 \t Time: 108 \t Test: 0.017 \t Train: 0.009 \t Accuracy: 99.4000\n",
      "Epoch:  28 \t Time: 108 \t Test: 0.017 \t Train: 0.009 \t Accuracy: 99.4600\n",
      "Epoch:  29 \t Time: 109 \t Test: 0.017 \t Train: 0.008 \t Accuracy: 99.4800\n",
      "Epoch:  30 \t Time: 110 \t Test: 0.019 \t Train: 0.008 \t Accuracy: 99.4100\n",
      "Epoch:  31 \t Time: 111 \t Test: 0.020 \t Train: 0.008 \t Accuracy: 99.3600\n",
      "Epoch:  32 \t Time: 111 \t Test: 0.017 \t Train: 0.007 \t Accuracy: 99.5300\n",
      "Epoch:  33 \t Time: 111 \t Test: 0.018 \t Train: 0.007 \t Accuracy: 99.4700\n",
      "Epoch:  34 \t Time: 111 \t Test: 0.016 \t Train: 0.006 \t Accuracy: 99.5000\n",
      "Epoch:  35 \t Time: 110 \t Test: 0.017 \t Train: 0.006 \t Accuracy: 99.4300\n",
      "Epoch:  36 \t Time: 108 \t Test: 0.016 \t Train: 0.006 \t Accuracy: 99.4700\n",
      "Epoch:  37 \t Time: 109 \t Test: 0.017 \t Train: 0.005 \t Accuracy: 99.3700\n",
      "Epoch:  38 \t Time: 108 \t Test: 0.017 \t Train: 0.005 \t Accuracy: 99.4100\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "Te_LOSS = []\n",
    "Tr_LOSS = []\n",
    "test_acc = []\n",
    "display_step = 450\n",
    "for epoch in range(max_epochs):\n",
    "  capsnet.train()\n",
    "  train_loss = 0\n",
    "  for batch, (data, target) in list(enumerate(train_loader)):\n",
    "    target = torch.eye(10).index_select(dim=0, index=target)\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    \n",
    "    if USE_GPU:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, reconstructions, masked = capsnet(data, target)\n",
    "    loss = capsnet.loss(data, target, output, reconstructions)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.data.item()\n",
    "    if batch % display_step == 0 and batch != 0:\n",
    "      eval_time = time.time()\n",
    "\n",
    "      capsnet.eval()\n",
    "      test_loss = 0\n",
    "      test_correct = 0\n",
    "      test_total = 0\n",
    "      for batch_id, (data, target) in enumerate(test_loader):\n",
    "        target = torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        if USE_GPU:\n",
    "          data,target = data.cuda(), target.cuda()\n",
    "\n",
    "        output, reconstruction, masked = capsnet(data)\n",
    "        loss = capsnet.loss(data, target, output, reconstruction)\n",
    "\n",
    "        test_loss += loss.data.item()\n",
    "        test_total += data.size(0)\n",
    "        test_correct += sum(np.argmax(masked.data.cpu().numpy(),1 ) == np.argmax(target.data.cpu().numpy(), 1))\n",
    "\n",
    "      acc = test_correct / test_total\n",
    "      Te_LOSS.append(test_loss / len(test_loader))\n",
    "      Tr_LOSS.append(train_loss / len(train_loader))\n",
    "      test_acc.append(acc)\n",
    "      test_loss /= len(test_loader)\n",
    "      train_loss /= len(train_loader)\n",
    "      time_spent = time.time() - t\n",
    "      t = time.time()\n",
    "      \n",
    "      print(\"Epoch: {:3.0f} \\t Time: {:3.0f} \\t Test: {:.3f} \\t Train: {:.3f} \\t Accuracy: {:3.4f}\".format(epoch, time_spent,test_loss, train_loss, acc*100))\n",
    "      train_loss = 0\n",
    "      filepath = path.join(SAVE_DIR, \"model{}.pt\".format(epoch))\n",
    "      torch.save(capsnet.state_dict(), filepath)\n",
    "      capsnet.train()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet.eval()\n",
    "data, target = iter(test_loader).next()\n",
    "output, reconstruction, masked = capsnet(data.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.max((output**2).sum(dim=2).squeeze(), dim=1)[1].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(target[i], predictions[i])\n",
    "im = reconstruction[i,0].data.cpu().numpy()\n",
    "im += abs(im.min())\n",
    "im /= im.max()\n",
    "plt.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
